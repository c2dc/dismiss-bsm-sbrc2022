{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocessingv2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOVxl9cS+vMUsRbygpRgd1A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZAw-Iqr8C12U","executionInfo":{"status":"ok","timestamp":1649100779542,"user_tz":180,"elapsed":19894,"user":{"displayName":"Fernando da Silva Dutra","userId":"15997828973746649324"}},"outputId":"f14d8a00-34e8-40fa-8896-08ce58c373e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import time\n","import json\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","rootPath = \"/content/drive/MyDrive/dataset/veremi\"\n","veremiPath = \"/veremi\"\n","t2Path = \"/veremiWithT2\"\n","csvt2Path = \"/simulationscsv\"\n","\n","os.chdir(rootPath+t2Path+csvt2Path)\n","\n","len(os.listdir())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7JgO4c2xEIOT","executionInfo":{"status":"ok","timestamp":1649100782830,"user_tz":180,"elapsed":3293,"user":{"displayName":"Fernando da Silva Dutra","userId":"15997828973746649324"}},"outputId":"300955a0-2de1-4e94-8fb6-6076e01ea953"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["225"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# preprocessing\n","mid = '/work/ul/ul_vertsys/ul_wqy57'\n","end = '/veins-maat/simulations/securecomm2018/results'\n","os.chdir(rootPath+veremiPath)\n","simulations = pd.Series(os.listdir()).sort_values().reset_index(drop=True)\n","totalsim = len(simulations)\n","os.chdir(rootPath+t2Path+csvt2Path)\n","# cria uma lista com todas simulações para execução parcial\n","if os.listdir():\n","  clist = []\n","  concluded = pd.Series(os.listdir()).sort_values().reset_index(drop=True)\n","  for concl in concluded.values:\n","    c = concl.split('.')\n","    clist.append(int(c[0][-3:]))\n","else:\n","  clist = []\n","tlist = list(set(range(totalsim)))\n","remainlist = list(set(tlist) - set(clist))\n","while remainlist:\n","  os.chdir(rootPath+t2Path+csvt2Path)\n","  concluded = pd.Series(os.listdir()).sort_values().reset_index(drop=True)\n","  clist = []\n","  for concl in concluded.values:\n","    c = concl.split('.')\n","    clist.append(int(c[0][-3:]))\n","  remainlist = list(set(tlist) - set(clist))\n","  # seleciona o item a ser processado\n","  if remainlist:\n","    item = 0\n","    sim = remainlist[item]\n","    szremainlist = len(remainlist)\n","    # start preprocess\n","    start_time = time.time()\n","    sims = simulations[sim]\n","    os.chdir(rootPath+veremiPath+'/'+sims+mid+'/'+sims+end)\n","    files = pd.Series(os.listdir()).sort_values().reset_index(drop=True)\n","    files = files.drop(index=files.loc[files.str.contains('.json') == False].index).reset_index(drop=True)\n","\n","    # ground truth\n","    dataGT = []\n","    with open(files[0]) as f:\n","      for line in f:\n","        try:\n","          dataGT.append(json.loads(line.strip()))\n","        except ValueError:\n","          pass\n","\n","    dataGT = pd.DataFrame(dataGT)\n","    # display(dataGT)\n","\n","    # retorna todas linhas daquela simulação\n","    dataLog = []\n","    lfiles = len(files[1:])\n","    for id, i in enumerate(files[1:], start=1):\n","      print('\\r',\n","            str(id)+'º de '+str(lfiles)+' | ',\n","            'reading simulation '+str(sim)+' |',\n","            \" in {:.2f}\".format(time.time() - start_time)+' sec',\n","            ' faltam '+str(szremainlist)+' simulações.',\n","            sep='', end='', flush=True)\n","      with open(files[id]) as f:\n","        for line in f:\n","          try:\n","            row = json.loads(line.strip())\n","            # add a receiver line to form the pair of communication\n","            row[\"receiver\"] = int(files[id].split(\"-\")[2])\n","            row[\"pxSnd\"] = row['pos'][0]\n","            row[\"pySnd\"] = row['pos'][1]\n","            row[\"pzSnd\"] = row['pos'][2]\n","            row[\"sxSnd\"] = row['spd'][0]\n","            row[\"sySnd\"] = row['spd'][1]\n","            row[\"szSnd\"] = row['spd'][2]\n","            dataLog.append(row)\n","          except ValueError:\n","            pass\n","\n","    dataLog = pd.DataFrame(dataLog)\n","\n","    # add the last know receiver's position \n","    vehicles = pd.Series(dataLog['receiver'].unique().astype(int)).sort_values().reset_index(drop=True)\n","    size = len(vehicles)\n","    # iv = vehicle index\n","    for iv, v in enumerate(vehicles):\n","      # if iv <= 0:\n","        # for each BSM (type 3) do this\n","        idxtype2 = dataLog.loc[(dataLog['receiver'].astype(int) == v) & (dataLog['type'] == 2)].index\n","        for tp in dataLog.loc[(dataLog['type'] == 3) & (dataLog['receiver'].astype(int) == v)].index:\n","          print('\\r',\n","                'simulation '+str(sim)+' |',\n","                ' vehicle '+str(iv+1)+' of '+str(size),\n","                \" in {:.2f}\".format(time.time() - start_time)+' sec |',\n","                ' faltam '+str(szremainlist)+' simulações.',\n","                sep='', end='', flush=True)\n","          poslist = dataLog['pos'].iloc[np.max(idxtype2[idxtype2 < tp])]\n","          spdlist = dataLog['spd'].iloc[np.max(idxtype2[idxtype2 < tp])]\n","          dataLog.at[tp, 'pxRcv'] = poslist[0]\n","          dataLog.at[tp, 'pyRcv'] = poslist[1]\n","          dataLog.at[tp, 'pzRcv'] = poslist[2]\n","          dataLog.at[tp, 'sxRcv'] = spdlist[0]\n","          dataLog.at[tp, 'syRcv'] = spdlist[1]\n","          dataLog.at[tp, 'szRcv'] = spdlist[2]\n","\n","    # Drop “Type2” in JSON files\n","    dataLog = dataLog.drop(dataLog[dataLog.type == 2].index).reset_index(drop=True)\n","\n","    # Drop pos, spd, type, noise, spd_noise, pos_noise in JSON files\n","    dataLog = dataLog.drop(columns=['pos', 'spd', 'type', 'noise', 'spd_noise', 'pos_noise']).reset_index(drop=True)\n","\n","    # Merge with ground truth to add labels\n","    dataLog = dataLog.merge(dataGT[['messageID', 'attackerType']])\n","\n","    # display(dataLog)\n","\n","    os.chdir(rootPath+t2Path+csvt2Path)\n","    print('\\rSaving sim'+f\"{remainlist[item]:03}\"+'.csv', sep='', end='', flush=True)\n","    dataLog.to_csv('sim'+f\"{remainlist[item]:03}\"+'.csv')\n","    \n","    # log the time of preprocessing\n","    os.chdir(rootPath+t2Path)\n","    simTime = time.time() - start_time\n","    data = {\"simulation\": \"sim\"+f\"{remainlist[item]:03}\", \"time\": simTime}\n","    try:\n","      timeDf = pd.read_csv('timePreprocessing.csv', index_col=0)\n","    except FileNotFoundError:\n","      timeDf = pd.DataFrame({\"simulation\": [data['simulation']], \"time\": [data['time']]})\n","      timeDf.to_csv('timePreprocessing.csv')\n","    else:\n","      if (timeDf['simulation'] == data['simulation']).any():\n","        timeDf.loc[timeDf['simulation'] == data['simulation'], ['time']] = data['time']\n","        timeDf.to_csv('timePreprocessing.csv')\n","      else:    \n","        timeDf = timeDf.append(data, ignore_index=True)\n","        timeDf.to_csv('timePreprocessing.csv')\n","\n","    # retira o item da remainlist\n","    remainlist.pop(item)\n","\n","os.chdir(rootPath+t2Path)\n","timeDf = pd.read_csv('timePreprocessing.csv', index_col=0)\n","print('\\rDone in ', \"{:.2f}\".format(timeDf['time'].sum())+' sec', sep='', end='', flush=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YuwV-PeEwzk","outputId":"7216d3a4-c8f0-427d-edc2-24baa31dd9e8","executionInfo":{"status":"ok","timestamp":1649100783785,"user_tz":180,"elapsed":957,"user":{"displayName":"Fernando da Silva Dutra","userId":"15997828973746649324"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\rDone in 84117.37 sec"]}]}]}